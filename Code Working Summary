Data Generation and Loading: You generated a synthetic dataset simulating library book borrowings, including issue dates, due dates, return dates, delays, and fines. This dataset was then loaded into a pandas DataFrame.
Exploratory Data Analysis (EDA): You performed EDA to understand the data's structure, identify missing values (none found in the synthetic data), and visualize distributions of key features like delay days and fines. You also explored relationships between categorical features and delays, and visualized feature correlations. The plots showed that 'Delay_Days' and 'Fine' are perfectly correlated, which makes sense given how the fine was calculated.
Preprocessing: You preprocessed the data by encoding categorical features using Label Encoding and converting date columns into numerical representations (days since the earliest date). Features were then scaled using StandardScaler.
Model Training and Evaluation: You split the data into training and testing sets and trained four different classification models to predict if a book would be returned late: Random Forest, Logistic Regression, Decision Tree, and Support Vector Machine (SVM).
Both the Random Forest and Decision Tree Classifiers achieved 100% accuracy on the test set, indicating they were able to perfectly classify whether a book was returned late or on time based on the features.
Logistic Regression also performed very well with high accuracy (around 99%).
The SVM model had a slightly lower accuracy (around 95%).
Confusion matrices and classification reports were generated for each model, providing more detailed insights into their performance (precision, recall, F1-score).
Feature Importance: You visualized the feature importance for the Random Forest and Decision Tree models, and the coefficients for the Logistic Regression model.
For the tree-based models, 'Delay_Days' was overwhelmingly the most important feature for predicting late returns.
For Logistic Regression, 'Delay_Days' also had the largest coefficient, indicating its strong positive influence on the prediction of a late return. Other date-related features and some categorical features also showed some influence.
In conclusion, the models, particularly Random Forest and Decision Tree, were highly effective at predicting late book returns based on the generated synthetic data, with 'Delay_Days' being the most influential feature.
